{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "[UNK][UNK][UNK][UNK][UNK][UNK]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.models.load_model('model/model.h5')\n",
    "# # model.summary()\n",
    "# # model.get_weights()\n",
    "\n",
    "img_path = \"img_predict/verifyImg.png\"\n",
    "max_length = 6\n",
    "img_width = 150\n",
    "img_height = 50\n",
    "\n",
    "prediction_model = keras.models.Model(\n",
    "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
    ")\n",
    "\n",
    "vocab = ['2', '3', '4', '5', '6', '7', '8', 'A', 'B', 'C', 'D', 'F', 'J', 'N', 'P', 'W', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'm', 'n', 'o', 'p', 'r', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    \n",
    "num_to_char = layers.StringLookup(\n",
    "    vocabulary=vocab, mask_token=None, invert=True\n",
    ")\n",
    "\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
    "        :, :max_length\n",
    "    ]\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text\n",
    "\n",
    "def classify_image(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    img = tf.transpose(img, perm=[1, 0, 2])\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    preds = prediction_model.predict(img)\n",
    "    pred_text = decode_batch_predictions(preds)\n",
    "    return pred_text[0]\n",
    "\n",
    "predict = classify_image(img_path)\n",
    "print(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
